{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VrWy5C5GEZNY"
   },
   "source": [
    "# Lime para texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T12:18:15.544142Z",
     "start_time": "2021-09-04T12:18:10.033392Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install 'scikit-learn==0.24.1'\n",
    "\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTLr53XzEZNZ"
   },
   "source": [
    "### Imports e demais inicializações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T12:18:24.901503Z",
     "start_time": "2021-09-04T12:18:15.552014Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2582,
     "status": "ok",
     "timestamp": 1588783186020,
     "user": {
      "displayName": "LILIANE LOURENÇA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgXmlR_Gx0KrqaA6Hg97u1-9IGT4GrBzFw6qXkAwA=s64",
      "userId": "01589378809252939986"
     },
     "user_tz": 180
    },
    "id": "Mk0N2U-1EZNa",
    "outputId": "d6a4443b-f7cd-4d3d-b69e-fb7217a268e1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cloudpickle\n",
    "from lime import lime_text\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "%run modules/data/text.py\n",
    "%run modules/features/processingFeatures.py\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(suppress=True, precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FqylHxFTW2r"
   },
   "source": [
    "### Carrega os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T12:18:26.807305Z",
     "start_time": "2021-09-04T12:18:24.907793Z"
    }
   },
   "outputs": [],
   "source": [
    "validacao = pd.read_csv('dataset/validacao_interpretabilidade.csv')\n",
    "validacao['paragrafos'] = validacao['paragrafos'].apply(cleaning)\n",
    "print(validacao.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrega o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T12:18:29.497559Z",
     "start_time": "2021-09-04T12:18:26.810419Z"
    }
   },
   "outputs": [],
   "source": [
    "model = cloudpickle.load(open('model/predict_lime.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T12:18:29.515809Z",
     "start_time": "2021-09-04T12:18:29.507615Z"
    }
   },
   "outputs": [],
   "source": [
    "class_names = ['dano material (0)', 'dano moral (1)']\n",
    "explainer = LimeTextExplainer(class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Gerando explicações para 1 instância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-03T13:43:42.625Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "idx = 100\n",
    "texto = validacao['paragrafos'][idx]\n",
    "exp = explainer.explain_instance(texto, model.predict_proba, num_features=6)\n",
    "listaExplicacao = exp.as_list()\n",
    "\n",
    "print('Documento id: %d' % idx)\n",
    "print('Classe predita', class_names[model.predict([texto])[0]])\n",
    "print('Classe real: %s' % validacao['categorias'][idx])\n",
    "print('\\nExplicação:')\n",
    "print ('\\n'.join(map(str, listaExplicacao)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-03T13:43:42.631Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Score(R²): ', exp.score)\n",
    "exp.show_in_notebook(text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliação das explicações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista gerado pelo Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T18:35:19.402641Z",
     "start_time": "2021-09-03T18:35:19.122418Z"
    }
   },
   "outputs": [],
   "source": [
    "def getLimeList(listaExplicacao):\n",
    "    lime_list = []\n",
    "    for palavras in listaExplicacao:\n",
    "        lime_list.append(palavras[0])\n",
    "    return lime_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lista com todas as palavras do texto ordenadas por importaância de acordo com a pontuação TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-03T18:35:19.533552Z",
     "start_time": "2021-09-03T18:35:19.405448Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def generateTfidfList(texto):\n",
    "    text_db = [cleaning(texto)]\n",
    "    tf_idf =  vectorizer.fit_transform(text_db)\n",
    "    result = pd.DataFrame(tf_idf.toarray(), columns=vectorizer.get_feature_names())\n",
    "    result = result.T.sort_values(by=0, ascending=False)\n",
    "    return result.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anotação Humana x Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T00:52:50.606747Z",
     "start_time": "2021-09-03T18:35:19.538922Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res = {'lime_list': [], 'humano_list': [], 'categoria': []}\n",
    "count = 0\n",
    "\n",
    "for i in range(len(validacao)):\n",
    "    count+=1    \n",
    "    if count%10==0:\n",
    "        print(f'Concluido etapa {count}')\n",
    "\n",
    "    texto = validacao['paragrafos'][i]     \n",
    "    exp = explainer.explain_instance(texto, model.predict_proba, num_features=6)\n",
    "    lime_list = getLimeList(exp.as_list())\n",
    "    res['lime_list'].append(lime_list)\n",
    "    res['humano_list'].append(validacao['trechos_tokens'][i])\n",
    "    res['categoria'].append(validacao['categorias'][i])\n",
    "frame = pd.DataFrame(res)\n",
    "frame.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-04T12:43:18.808540Z",
     "start_time": "2021-09-04T12:43:18.756297Z"
    }
   },
   "outputs": [],
   "source": [
    "resultado = pd.read_csv('dataset/result_lime_humano.csv')\n",
    "resultado['lime_list'] = resultado['lime_list'].apply(prepare)\n",
    "resultado['humano_list'] = resultado['humano_list'].apply(prepare)\n",
    "\n",
    "acerto = 0\n",
    "scores = []\n",
    "\n",
    "for i in range(len(resultado)):\n",
    "    for lime in resultado['lime_list'][i]:\n",
    "        if lime in resultado['humano_list'][i]:\n",
    "            acerto+=1\n",
    "    scores.append(acerto / len(resultado['humano_list'][i])*100)\n",
    "    acerto = 0\n",
    "print('% médio de acertos: ', np.mean(scores).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coeficiente de correlação de classificação de Kendall\n",
    "\n",
    "> É uma medida de correspondência entre duas classificações. Valores próximos a 1 indicam forte concordância e valores próximos a -1 indicam forte discordância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-31T11:21:14.008227Z",
     "start_time": "2021-08-31T11:21:14.002896Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def calculateTauKendall(lime_list, tfidf_list):\n",
    "    interim_list = []\n",
    "    for word in tfidf_list:\n",
    "        if word in lime_list and word not in interim_list:\n",
    "            interim_list.append(word)\n",
    "    tau, p_value = stats.kendalltau(lime_list, interim_list)\n",
    "    print(interim_list)\n",
    "    return tau, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gera a explicação para toda a base de validação e calcula a média para o tau de kendall e o p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T16:41:16.915589Z",
     "start_time": "2021-08-29T10:42:06.324829Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_tau = []\n",
    "scores_rquadrado = []\n",
    "p_values = []\n",
    "for i in range(len(validacao)):\n",
    "    texto = validacao['paragrafos'][i]     \n",
    "    exp = explainer.explain_instance(texto, model.predict_proba, num_features=6)\n",
    "    \n",
    "    scores_rquadrado.append(exp.score)\n",
    "    \n",
    "    lime_list = getLimeList(exp.as_list())\n",
    "    tfidf_list = generateTfidfList(texto)\n",
    "    \n",
    "    tau, p_value = calculateTauKendall(lime_list, tfidf_list)\n",
    "    scores_tau.append(tau)\n",
    "    p_values.append(p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando o p-value: \n",
    "> **H0**: As amostras não estão correlacionada\n",
    "\n",
    "> **H1**: As amostras estão correlacionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-29T18:56:48.061618Z",
     "start_time": "2021-08-29T18:56:48.052630Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Tau para 500 exemplos: ', np.mean(scores_tau).round(3))\n",
    "print('Score médio para 500 exemplos: ', np.mean(scores_rquadrado).round(3))\n",
    "\n",
    "alpha = 0.05\n",
    "p = np.mean(p_values)\n",
    "if p > alpha:\n",
    "    print('As amostras não são correlacionadas (falha em rejeitar H0) p=%.3f' % p)\n",
    "else:\n",
    "    print('As amostras são correlacionadas (rejeita H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score médio das explicações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-28T13:12:00.249Z"
    }
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(validacao)):\n",
    "    texto = cleaning(validacao['paragrafos'][i])                     \n",
    "    exp = explainer.explain_instance(texto, model.predict_proba, num_features=6)\n",
    "    scores.append(exp.score)\n",
    "print('Score médio para 500 exemplos: ', np.mean(scores).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão, revocação e F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-28T13:12:00.403Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def getMetrics(lime_list, tfidf_list):\n",
    "    len_lime_list =  len(lime_list)\n",
    "    len_tfidf_list = len(tfidf_list)\n",
    "    total_palavras_tfidf_list_em_lime_list = 0\n",
    "\n",
    "    for i in range(len_lime_list):\n",
    "        if tfidf_list[i] in lime_list:\n",
    "            total_palavras_tfidf_list_em_lime_list += 1\n",
    "\n",
    "    sublist_lime_len = len_lime_list\n",
    "    while total_palavras_tfidf_list_em_lime_list != len_lime_list:\n",
    "        if tfidf_list[sublist_lime_len] in lime_list:\n",
    "            total_palavras_tfidf_list_em_lime_list += 1\n",
    "        sublist_lime_len += 1\n",
    "\n",
    "    recall = sublist_lime_len / len_tfidf_list\n",
    "    precision = len_lime_list / sublist_lime_len\n",
    "    f1_score = 2 * precision * recall / (precision + recall)\n",
    "    return recall, precision, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-08-28T13:12:00.438Z"
    }
   },
   "outputs": [],
   "source": [
    "recall, precision, f1_score = getMetrics(lime_list, tfidf_list)\n",
    "print(f' Precisão: {precision}')\n",
    "print(f' Recall: {recall}')\n",
    "print(f'F1-escore: {f1_score}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ModelsSubtipos.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "574.974px",
    "width": "355.695px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
